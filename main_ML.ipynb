{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "!pip install ucimlrepo pandas numpy matplotlib seaborn scikit-learn statsmodels mlxtend\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import sklearn\n",
    "import random\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "from itertools import combinations\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression, LassoCV, ElasticNetCV, Ridge, Lasso, ElasticNet, RidgeCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from itertools import product, combinations\n",
    "from collections import Counter"
   ],
   "id": "fbc121e30a2defb3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# fetch the dataset from UCI server\n",
    "com_and_crime = fetch_ucirepo(id=183)\n",
    "\n",
    "# Extract features and targets\n",
    "X = com_and_crime.data.features\n",
    "y = com_and_crime.data.targets\n",
    "\n",
    "# Create combined dataframe\n",
    "df = pd.concat([X, y], axis=1)\n",
    "\n",
    "# ~Part 0: Data Preprocessing~\n",
    "# Replace '?' with NaN\n",
    "df.replace('?', np.nan, inplace=True)\n",
    "\n",
    "# Show Metadata and see distribution of the data\n",
    "print(com_and_crime.metadata)\n",
    "print(\"Initial shape:\", df.shape)\n",
    "print(df.describe())\n",
    "df.hist(bins=30, figsize=(12, 8))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Identify columns with high missing values\n",
    "missing = df.isna().mean().sort_values(ascending=False)\n",
    "high_missing = missing[missing > 0.4].index\n",
    "print(\"Columns with >40% missing values:\", high_missing.tolist())\n",
    "\n",
    "# Remove columns with >40% missing values\n",
    "df.drop(columns=high_missing, inplace=True)\n",
    "# Remove non-predictive columns\n",
    "df.drop(columns=['communityname', 'state', 'county', 'community', 'fold'],inplace=True, errors='ignore')\n",
    "\n",
    "# Check which column is still non-numerical after removal of columns\n",
    "object_cols = [col for col in df.columns if df[col].dtype == 'object']\n",
    "print(object_cols)\n",
    "\n",
    "# Convert the column into floating and check if conversion is successful\n",
    "df['OtherPerCap'] = pd.to_numeric(df['OtherPerCap'], errors='coerce')\n",
    "print(df.OtherPerCap)\n",
    "\n",
    "# Impute a value for the only missing value in OtherPerCap\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "df['OtherPerCap'] = imputer.fit_transform(df[['OtherPerCap']])\n",
    "\n",
    "# Ensure there is no more missing value\n",
    "print(\"Remaining missing values:\", df.isna().sum().sum())\n",
    "\n",
    "# Compute the correlation matrix and plot the heatmap to get a sense of what is happening in dataset\n",
    "corr_matrix = df.corr()\n",
    "print(corr_matrix)\n",
    "plt.figure(figsize=(14, 10))\n",
    "sns.heatmap(corr_matrix, cmap='coolwarm', center=0, annot=False)\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()"
   ],
   "id": "3cace6068592d2bf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ~Part 1: Data Analysis~\n",
    "# (a) (i) Compare and contrast\n",
    "# Split dataset into features and target\n",
    "X = df.drop(columns=['ViolentCrimesPerPop'])\n",
    "y = df['ViolentCrimesPerPop']\n",
    "print(X)\n",
    "print(y)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# 1 Least Square method\n",
    "num_features = 10\n",
    "X_const = sm.add_constant(X)\n",
    "ols_model = sm.OLS(y, X_const).fit()\n",
    "\n",
    "# Get p-values and sort features by significance\n",
    "ols_pvalues = ols_model.pvalues.sort_values()\n",
    "print(\"Top features based on Least Squares p-values:\")\n",
    "print(ols_pvalues.head(num_features))\n",
    "\n",
    "# 2 Best Subset: use smaller set of‚ê£pre-selected features as determined by significance\n",
    "significant_features = ols_pvalues[ols_pvalues < 0.01].index.drop(\"const\", errors=\"ignore\") # Remove intercept\n",
    "X_significant = X[significant_features]\n",
    "\n",
    "def best_subset(X, y):\n",
    "    best_score = float(\"inf\")\n",
    "    best_features = None\n",
    "\n",
    "    for subset in combinations(X.columns, num_features):\n",
    "        X_sub = X[list(subset)]\n",
    "        X_sub_const = sm.add_constant(X_sub)\n",
    "        model = sm.OLS(y, X_sub_const).fit()\n",
    "        score = model.aic # Use AIC to evaluate model\n",
    "\n",
    "        if score < best_score:\n",
    "            best_score = score\n",
    "            best_features = subset\n",
    "\n",
    "    return best_features\n",
    "\n",
    "best_features = best_subset(X_significant, y)\n",
    "print(\"Best subset features:\")\n",
    "print(\"\\n\".join(best_features))\n",
    "\n",
    "# 3 Best feature from RFE\n",
    "rfe = RFE(LinearRegression(), n_features_to_select=num_features)\n",
    "rfe.fit(X_scaled, y)\n",
    "selected_features = X.columns[rfe.support_]\n",
    "print(\"Top features from RFE:\")\n",
    "print(\"\\n\".join(selected_features))\n",
    "\n",
    "# 4 Lasso Selection\n",
    "lasso = LassoCV(cv=5).fit(X_scaled, y)\n",
    "lasso_coefs = pd.Series(lasso.coef_, index=X.columns)\n",
    "\n",
    "# Interpret most important features as those with largest absolute weight\n",
    "top_lasso_features = np.abs(lasso_coefs).sort_values(ascending=False)\n",
    "print(\"Top Lasso Features:\")\n",
    "print(top_lasso_features[:num_features])\n",
    "\n",
    "# 5 Elastic Net Selection\n",
    "elastic_net = ElasticNetCV(cv=5).fit(X_scaled, y)\n",
    "enet_coefs = pd.Series(elastic_net.coef_, index=X.columns)\n",
    "\n",
    "# Interpret most important features as those with largest absolute weight\n",
    "top_enet_features = np.abs(enet_coefs).sort_values(ascending=False)\n",
    "print(\"Top Elastic Net Features:\")\n",
    "print(top_enet_features[:num_features])\n",
    "\n",
    "# Compile result\n",
    "results = {\n",
    "    \"OLS Significance\": ols_pvalues,\n",
    "    \"Best Subsets\": best_features,\n",
    "    \"RFE\": selected_features,\n",
    "    \"Lasso\": top_lasso_features,\n",
    "    \"Elastic Net\": top_enet_features\n",
    "}\n",
    "\n",
    "\n",
    "# Aggregate feature votes from respective methods to see which features get picked the most or the least\n",
    "all_features = [f for sublist in results.values() for f in sublist]\n",
    "feature_counts = Counter(all_features)\n",
    "\n",
    "# Plot feature importance consensus\n",
    "plt.figure(figsize=(20, 20))\n",
    "pd.Series(feature_counts).sort_values().plot(kind='barh')\n",
    "plt.title('Feature Selection Consensus Across Methods')\n",
    "plt.xlabel('Number of Methods Selecting Feature')\n",
    "plt.ylabel('Features')\n",
    "plt.show()\n",
    "\n",
    "# Plot heatmap for showing the features picked by each method\n",
    "comparison_df = pd.DataFrame(index=X_scaled.columns)\n",
    "for results, features in results.items():\n",
    "    comparison_df[results] = comparison_df.index.isin(features).astype(int)\n",
    "\n",
    "plt.figure(figsize=(30, 30))\n",
    "sns.heatmap(comparison_df.T, cmap='Blues')\n",
    "plt.title(\"Feature Presence Across Methods\")\n",
    "plt.xlabel(\"Features\")\n",
    "plt.ylabel(\"Selection Methods\")\n",
    "plt.show()"
   ],
   "id": "4f9290932c6082ad"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Fit and visualize regularization path\n",
    "\n",
    "# Lasso and Ridge\n",
    "alphas = np.logspace(-4, 1, 50)\n",
    "\n",
    "lasso_coefs = []\n",
    "ridge_coefs = []\n",
    "\n",
    "for alpha in alphas:\n",
    "    lasso = Lasso(alpha=alpha, max_iter=5000)\n",
    "    lasso.fit(X_scaled, y)\n",
    "    lasso_coefs.append(lasso.coef_)\n",
    "    ridge = Ridge(alpha=alpha)\n",
    "    ridge.fit(X_scaled, y)\n",
    "    ridge_coefs.append(ridge.coef_)\n",
    "\n",
    "lasso_coefs = np.array(lasso_coefs)\n",
    "ridge_coefs = np.array(ridge_coefs)\n",
    "\n",
    "# Elastic Net with two different alphas\n",
    "\n",
    "alpha_1 = 0.3\n",
    "alpha_2 = 0.7\n",
    "\n",
    "l1_ratios = np.linspace(0.1, 0.9, 50) # From mostly Ridge to mostly Lasso\n",
    "\n",
    "elastic_net_coefs_1 = []\n",
    "elastic_net_coefs_2 = []\n",
    "\n",
    "for l1_ratio in l1_ratios:\n",
    "    # Elastic Net with first alpha\n",
    "    elastic_net_1 = ElasticNet(alpha=alpha_1, l1_ratio=l1_ratio, max_iter=5000)\n",
    "    elastic_net_1.fit(X_scaled, y)\n",
    "    elastic_net_coefs_1.append(elastic_net_1.coef_)\n",
    "\n",
    "    # Elastic Net with second alpha\n",
    "    elastic_net_2 = ElasticNet(alpha=alpha_2, l1_ratio=l1_ratio, max_iter=5000)\n",
    "    elastic_net_2.fit(X_scaled, y)\n",
    "    elastic_net_coefs_2.append(elastic_net_2.coef_)\n",
    "\n",
    "elastic_net_coefs_1 = np.array(elastic_net_coefs_1)\n",
    "elastic_net_coefs_2 = np.array(elastic_net_coefs_2)\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "# Lasso\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(alphas, lasso_coefs)\n",
    "plt.xscale(\"log\")\n",
    "plt.xlabel(\"Alpha\")\n",
    "plt.ylabel(\"Coefficients\")\n",
    "plt.title(\"Lasso Path\")\n",
    "\n",
    "# Ridge\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(alphas, ridge_coefs)\n",
    "plt.xscale(\"log\")\n",
    "plt.xlabel(\"Alpha\")\n",
    "plt.ylabel(\"Coefficients\")\n",
    "plt.title(\"Ridge Path\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot Elastic Net regularization paths\n",
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "# Elastic Net (Alpha 1)\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(l1_ratios, elastic_net_coefs_1)\n",
    "plt.xlabel(\"L1 Ratio\")\n",
    "plt.ylabel(\"Coefficients\")\n",
    "plt.title(f\"Elastic Net Path (Alpha = {alpha_1})\")\n",
    "\n",
    "# Elastic Net (Alpha 2)\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(l1_ratios, elastic_net_coefs_2)\n",
    "plt.xlabel(\"L1 Ratio\")\n",
    "plt.ylabel(\"Coefficients\")\n",
    "plt.title(f\"Elastic Net Path (Alpha = {alpha_2})\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "cc590b814885f8e4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# We create the results dictionary to keep track of the mean squared error (MSE) for each method.\n",
    "# Notably, for each iteration, we split the data as instructed and scale X_train. We use the same scaling for X_train on X_val and X_test.\n",
    "# For any method that has tunable hyperparameters, on each iteration we use grid search to find a value of the hyperparameter that minimizes the MSE on the validation set, and then we use this value to fit the model and evaluate it on the test set. For RFE, the hyperparameter is the proportion of features we use.\n",
    "\n",
    "num_iterations = 10\n",
    "results = {\n",
    "    \"Least Squares\": [],\n",
    "    \"Ridge\": [],\n",
    "    \"Best Subsets\": [],\n",
    "    \"RFE\": [],\n",
    "    \"Lasso\": [],\n",
    "    \"Elastic Net\": []\n",
    "}\n",
    "\n",
    "for _ in range(num_iterations):\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4)\n",
    "    scaler_X_train = StandardScaler()\n",
    "    X_train = pd.DataFrame(scaler_X_train.fit_transform(X_train), columns=X.columns)\n",
    "\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5)\n",
    "    X_val = pd.DataFrame(scaler_X_train.transform(X_val), columns=X_val.columns)\n",
    "    X_test = pd.DataFrame(scaler_X_train.transform(X_test), columns=X_test.columns)\n",
    "\n",
    "    # Least Squares\n",
    "    model_ls = LinearRegression().fit(X_train, y_train)\n",
    "    y_pred_ls = model_ls.predict(X_test)\n",
    "    results[\"Least Squares\"].append(mean_squared_error(y_test, y_pred_ls))\n",
    "\n",
    "    # Ridge Regression\n",
    "    best_alpha = min(\n",
    "        np.arange(0.1, 1.1, 0.1),\n",
    "        key=lambda a: mean_squared_error(y_val, Ridge(alpha=a).fit(X_train, y_train).predict(X_val))\n",
    "    )\n",
    "    model_ridge = Ridge(alpha=best_alpha).fit(X_train, y_train)\n",
    "    y_pred_ridge = model_ridge.predict(X_test)\n",
    "    results[\"Ridge\"].append(mean_squared_error(y_test, y_pred_ridge))\n",
    "\n",
    "    # Best Subsets\n",
    "    best_features = best_subset(X_significant, y)\n",
    "    model_best_subset = LinearRegression().fit(X_train[list(best_features)], y_train)\n",
    "    y_pred_best_subset = model_best_subset.predict(X_test[list(best_features)])\n",
    "    results[\"Best Subsets\"].append(mean_squared_error(y_test, y_pred_best_subset))\n",
    "\n",
    "    # Recursive Feature Elimination\n",
    "    def evaluate_prop(prop):\n",
    "        selector = RFE(LinearRegression(), n_features_to_select=prop)\n",
    "        selector.fit(X_val, y_val)\n",
    "        selected_features = X_val.columns[selector.support_]\n",
    "        model_val = LinearRegression().fit(X_val[selected_features], y_val)\n",
    "        y_pred_val = model_val.predict(X_val[selected_features])\n",
    "\n",
    "        return mean_squared_error(y_val, y_pred_val)\n",
    "\n",
    "    best_prop = min(np.arange(0.1, 1, 0.1), key=evaluate_prop)\n",
    "    rfe = RFE(LinearRegression(), n_features_to_select=best_prop)\n",
    "    selector = rfe.fit(X_train, y_train)\n",
    "    selected_features = X_train.columns[selector.support_]\n",
    "    model_rfe = LinearRegression().fit(X_train[selected_features], y_train)\n",
    "    y_pred_rfe = model_rfe.predict(X_test[selected_features])\n",
    "    results[\"RFE\"].append(mean_squared_error(y_test, y_pred_rfe))\n",
    "\n",
    "    # Lasso\n",
    "    best_alpha = min(\n",
    "    np.logspace(-4, 1, 10),\n",
    "    key=lambda a: mean_squared_error(y_val, Lasso(alpha=a,max_iter=10000).fit(X_train, y_train).predict(X_val)))\n",
    "\n",
    "    model_lasso = Lasso(alpha=best_alpha, max_iter=10000).fit(X_train, y_train)\n",
    "    y_pred_lasso = model_lasso.predict(X_test)\n",
    "    results[\"Lasso\"].append(mean_squared_error(y_test, y_pred_lasso))\n",
    "\n",
    "    # Elastic Net\n",
    "    alpha_values = np.logspace(-4, 1, 10)\n",
    "    l1_ratio_values = np.arange(0.1, 1.1, 0.1)\n",
    "    best_alpha, best_l1_ratio = min(\n",
    "        [(a, l1) for a in alpha_values for l1 in l1_ratio_values],\n",
    "        key=lambda params: mean_squared_error(\n",
    "            y_val, ElasticNet(alpha=params[0], l1_ratio=params[1], max_iter=10000).fit(X_train, y_train).predict(X_val)\n",
    "        )\n",
    "    )\n",
    "    model_elastic = ElasticNet(alpha=best_alpha, l1_ratio=best_l1_ratio, max_iter=10000).fit(X_train, y_train)\n",
    "    y_pred_elastic = model_elastic.predict(X_test)\n",
    "    results[\"Elastic Net\"].append(mean_squared_error(y_test, y_pred_elastic))"
   ],
   "id": "9026f14ab5eb8ad6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Visualize the results\n",
    "\n",
    "import seaborn as sns\n",
    "mse_data = []\n",
    "\n",
    "for method, mse_values in results.items():\n",
    "    for mse in mse_values:\n",
    "        mse_data.append({\"Method\": method, \"MSE\": mse})\n",
    "\n",
    "df_mse = pd.DataFrame(mse_data)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x=\"Method\", y=\"MSE\", data=df_mse)\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"Comparison of Prediction MSE Across Methods\")\n",
    "plt.ylabel(\"Mean Squared Error (MSE)\")\n",
    "plt.xlabel(\"Method\")\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.show()"
   ],
   "id": "568597672a6ccca4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# code up K-fold cross-validation from scratch\n",
    "\n",
    "def get_folds(X, num_folds):\n",
    "    folds = []\n",
    "    fold_size = len(X) // num_folds\n",
    "    indices = list(range(len(X)))\n",
    "    random.shuffle(indices)\n",
    "\n",
    "    for fold in range(num_folds):\n",
    "        left_index = fold * fold_size\n",
    "        right_index = min((fold + 1) * fold_size, len(X) - 1)\n",
    "        test_indices = indices[left_index:right_index]\n",
    "        train_indices = [i for i in indices if i not in test_indices]\n",
    "\n",
    "        folds.append((train_indices, test_indices))\n",
    "\n",
    "    return folds\n",
    "\n",
    "def cross_validation(X, y, params, model_fn, score_fn, fit_fn = None, num_folds=5):\n",
    "    # Create a dictionary where each element has the form\n",
    "    # (('alpha', 1), ('gamma', 4), ('kernel', 'poly')): []\n",
    "    # and so on, for each combination of parameter values\n",
    "\n",
    "    scores = {\n",
    "        tuple(dict(zip(params.keys(), values)).items()): []\n",
    "        for values in product(*params.values())\n",
    "    }\n",
    "\n",
    "    for fold in get_folds(X, num_folds):\n",
    "        train_indices, test_indices = fold\n",
    "        X_train, X_test = X.iloc[train_indices], X.iloc[test_indices]\n",
    "        y_train, y_test = y.iloc[train_indices], y.iloc[test_indices]\n",
    "\n",
    "        for param in scores:\n",
    "            param_dict = dict(param)\n",
    "            model = model_fn(**param_dict)\n",
    "            if not fit_fn:\n",
    "                model = model.fit(X_train, y_train)\n",
    "\n",
    "            else:\n",
    "                model = fit_fn(model, X_train, y_train)\n",
    "\n",
    "            y_pred = model.predict(X_test)\n",
    "            scores[param].append(score_fn(y_test, y_pred))\n",
    "\n",
    "    # Return the params with the smallest average score among the folds\n",
    "    best_param = min(scores, key=lambda param : sum(scores[param]) / len(scores[param]))\n",
    "    best_score = sum(scores[best_param]) / len(scores[best_param])\n",
    "\n",
    "    best_param_dict = dict(best_param)\n",
    "    best_param_dict['score'] = best_score\n",
    "    return best_param_dict"
   ],
   "id": "db4a6680ae18c55d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# use the function above to tune the alpha and gamma hyperparameters for the polynomial and RBF kernels. We use the default set above at 5 folds to keep the runtime reasonable, but 10 is also a common choice\n",
    "\n",
    "# Define search space for hyperparameters\n",
    "alpha_values = np.logspace(-3, 2, 10)\n",
    "gamma_values = np.logspace(-3, 2, 10)\n",
    "\n",
    "# Finding the best hyperparameters for Polynomial kernel\n",
    "poly_results = cross_validation(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    params = {\n",
    "        'alpha': alpha_values,\n",
    "        'gamma': gamma_values,\n",
    "        'kernel': ['poly'],\n",
    "    },\n",
    "    model_fn = lambda param: KernelRidge(**param),\n",
    "    score_fn = mean_squared_error,\n",
    "    num_folds = 5,\n",
    ")\n",
    "\n",
    "print(f\"For the polynomial kernel:\")\n",
    "print(f\"Best alpha: {poly_results['alpha']}\")\n",
    "print(f\"Best gamma: {poly_results['gamma']}\")\n",
    "print(f\"MSE: {poly_results['score']}\")"
   ],
   "id": "dcc1c82c6dad5ff4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Find the best hyperparameters for RBF kernel\n",
    "\n",
    "rbf_results = cross_validation(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    params = {\n",
    "        'alpha': alpha_values,\n",
    "        'gamma': gamma_values,\n",
    "        'kernel': ['rbf'],\n",
    "    },\n",
    "    model_fn = lambda param: KernelRidge(**param),\n",
    "    score_fn = mean_squared_error,\n",
    "    num_folds = 5,\n",
    ")\n",
    "\n",
    "print(f\"For the rbf kernel:\")\n",
    "print(f\"Best alpha: {rbf_results['alpha']}\")\n",
    "print(f\"Best gamma: {rbf_results['gamma']}\")\n",
    "print(f\"MSE: {rbf_results['score']}\")"
   ],
   "id": "d9fd8e28661bfefe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Compare with the built-in cross-validation function in sklearn\n",
    "\n",
    "param_grid_poly = {'alpha': alpha_values, 'gamma': gamma_values, 'kernel': ['poly']}\n",
    "param_grid_rbf = {'alpha': alpha_values, 'gamma': gamma_values, 'kernel': ['rbf']}\n",
    "poly_model = GridSearchCV(KernelRidge(), param_grid_poly, cv=5, scoring='neg_mean_squared_error')\n",
    "rbf_model = GridSearchCV(KernelRidge(), param_grid_rbf, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "poly_model.fit(X_train, y_train)\n",
    "rbf_model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Sklearn CV - Polynomial\")\n",
    "print(f\"Alpha = {poly_model.best_params_['alpha']}\")\n",
    "print(f\"Gamma = {poly_model.best_params_['gamma']}\")\n",
    "print(f\"MSE = {-poly_model.best_score_}\")\n",
    "\n",
    "print(\"\\nSklearn CV - RBF\")\n",
    "print(f\"Alpha = {rbf_model.best_params_['alpha']}\")\n",
    "print(f\"Gamma = {rbf_model.best_params_['gamma']}\")\n",
    "print(f\"MSE = {-rbf_model.best_score_}\")"
   ],
   "id": "316bdd5fde1e8723"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# compare the RBF and polynomial kernel ridge models with self-defined CV function to the linear regression models from previous sections\n",
    "\n",
    "num_features = 10\n",
    "\n",
    "# Least Squares\n",
    "X_train_const = sm.add_constant(X_train).reset.index(drop=True)\n",
    "y_train_ols = y_train.copy().reset_index(drop=True)\n",
    "model_ols = sm.OLS(y_train, X_train_const).fit()\n",
    "\n",
    "# Best subset\n",
    "best_features = best_subset(X_significant, y_train_ols)\n",
    "model_best_subset = LinearRegression().fit(X_train_const[list(best_features)], y_train_ols)\n",
    "\n",
    "# Fit RFE using CV on the proportion of features used\n",
    "# To understand what this algorithm is doing, note that for a fixed proportion p, we frst use RFE to select the most important p * 100% features and then ft OLS on those.\n",
    "# Using the CV algorithm we built earlier isn‚Äôt straight forward due to the fact that we need to keep track of which features we are using as predictors, but the algorithm is mostly the same.\n",
    "\n",
    "proportions = np.linspace(0.1, 0.9, 9)\n",
    "model_rfe = None\n",
    "model_rfe_features = None\n",
    "\n",
    "for fold in get_folds(X_train, num_folds=5):\n",
    "    train_indices, test_indices = fold\n",
    "    X_train_cv, y_train_cv = X_train[train_indices], y_train[train_indices]\n",
    "    X_val_cv, y_val_cv = X_train[test_indices], y_train[test_indices]\n",
    "\n",
    "    best_MSE = float(\"inf\")\n",
    "\n",
    "    for prop in proportions:\n",
    "        rfe = RFE(LinearRegression(), n_features_to_select=prop)\n",
    "        rfe.fit(X_train_cv, y_train_cv)\n",
    "        selected_features = X_train_cv.columns[rfe.support_]\n",
    "\n",
    "        curr_model = LinearRegression().fit(X_train_cv[selected_features], y_train_cv)\n",
    "        curr_MSE = mean_squared_error(y_val_cv, curr_model.predict(X_val_cv[selected_features]))\n",
    "\n",
    "        if curr_MSE < best_MSE:\n",
    "            best_MSE = curr_MSE\n",
    "            model_rfe = curr_model\n",
    "            model_rfe_features = selected_features\n",
    "\n",
    "# Fit LASSO using built-in CV\n",
    "model_lasso = LassoCV(cv=5).fit(X_train, y_train)\n",
    "\n",
    "# Fit Elastic Net using built-in CV\n",
    "model_elastic_net = ElasticNetCV(cv=5).fit(X_train, y_train)\n",
    "\n",
    "# Fit Ridge using built-in CV\n",
    "model_ridge = RidgeCV(cv=5).fit(X_train, y_train)"
   ],
   "id": "73930482dae6008e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Compare models on test set\n",
    "\n",
    "# Polynomial kernel\n",
    "y_pred_poly = poly_model.predict(X_test)\n",
    "mse_poly = mean_squared_error(y_test, y_pred_poly)\n",
    "\n",
    "# RBF kernel\n",
    "y_pred_rbf = rbf_model.predict(X_test)\n",
    "mse_rbf = mean_squared_error(y_test, y_pred_rbf)\n",
    "\n",
    "# OLS\n",
    "X_test_const = sm.add_constant(X_test)\n",
    "y_pred_ols = model_ols.predict(X_test_const)\n",
    "mse_ols = mean_squared_error(y_test, y_pred_ols)\n",
    "\n",
    "# Best Subsets\n",
    "y_pred_best_subset = model_best_subset.predict(X_test_const[list(best_features)])\n",
    "mse_best_subset = mean_squared_error(y_test, y_pred_best_subset)\n",
    "\n",
    "# RFE\n",
    "y_pred_rfe = model_rfe.predict(X_test[model_rfe_features])\n",
    "mse_rfe = mean_squared_error(y_test, y_pred_rfe)\n",
    "\n",
    "# LASSO\n",
    "y_pred_lasso = model_lasso.predict(X_test)\n",
    "mse_lasso = mean_squared_error(y_test, y_pred_lasso)\n",
    "\n",
    "# Elastic Net\n",
    "y_pred_elastic_net = model_elastic_net.predict(X_test)\n",
    "mse_elastic_net = mean_squared_error(y_test, y_pred_elastic_net)\n",
    "\n",
    "# Ridge\n",
    "y_pred_ridge = model_ridge.predict(X_test)\n",
    "mse_ridge = mean_squared_error(y_test, y_pred_ridge)\n",
    "\n",
    "print(f\"MSE for the polynomial kernel: {mse_poly}\")\n",
    "print(f\"MSE for the RBF kernel: {mse_rbf}\")\n",
    "print(f\"MSE for OLS: {mse_ols}\")\n",
    "print(f\"MSE for Best Subsets: {mse_best_subset}\")\n",
    "print(f\"MSE for RFE: {mse_rfe}\")\n",
    "print(f\"MSE for LASSO: {mse_lasso}\")\n",
    "print(f\"MSE for Elastic Net: {mse_elastic_net}\")\n",
    "print(f\"MSE for Ridge: {mse_ridge}\")"
   ],
   "id": "57095a467473fb61"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
